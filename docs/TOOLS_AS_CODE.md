# Tools-as-Code Pattern - Experimental Implementation

This document describes the experimental "tools-as-code" pattern implementation inspired by [Anthropic's approach](https://www.anthropic.com/engineering/code-execution-with-mcp).

## ðŸ“‹ Table of Contents

1. [Overview](#overview)
2. [Architecture](#architecture)
3. [Usage](#usage)
4. [Creating New Tools](#creating-new-tools)
5. [Testing](#testing)
6. [Benefits](#benefits)
7. [Migration Guide](#migration-guide)

## Overview

### What is Tools-as-Code?

Instead of registering all tools upfront in the MCP server (which can consume 150K+ tokens), the tools-as-code pattern:

1. **Only exposes a single `search_tool`** that agents use to discover other tools
2. **Loads tools dynamically** from the filesystem on-demand
3. **Supports progressive disclosure** with three detail levels:
   - `minimal`: Just name and category (~5 tokens/tool)
   - `standard`: Name, description, category, tags (~20 tokens/tool)
   - `full`: Complete input/output schemas (~50-100 tokens/tool)

### Token Savings

**Before (Traditional):**
- 8 tools Ã— 50 tokens = 400 tokens loaded upfront
- All tools always visible to the agent

**After (Tools-as-Code):**
- 1 search_tool Ã— 50 tokens = 50 tokens initially
- Agent discovers only needed tools (2-3 tools typical) = ~150 tokens total
- **~98.7% token reduction** for large tool sets (as reported by Anthropic)

## Architecture

### Directory Structure

```
src/teradata_mcp/
â”œâ”€â”€ tools/                          # Tools-as-Code implementation
â”‚   â”œâ”€â”€ __init__.py                # Package exports
â”‚   â”œâ”€â”€ base.py                    # Base classes (ToolBase, ToolMetadata, etc.)
â”‚   â”œâ”€â”€ executor.py                # ToolExecutor for dynamic loading
â”‚   â”œâ”€â”€ search.py                  # SearchTool implementation
â”‚   â”œâ”€â”€ database/                  # Database category tools
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ query.py              # SQL query tool
â”‚   â”‚   â”œâ”€â”€ list_db.py            # List databases tool
â”‚   â”‚   â”œâ”€â”€ list_tables.py        # List tables tool
â”‚   â”‚   â””â”€â”€ show_tables_details.py
â”‚   â””â”€â”€ analytics/                 # Analytics category tools
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ list_missing_values.py
â”‚       â””â”€â”€ standard_deviation.py
â”œâ”€â”€ fnc_tools_dynamic.py           # Dynamic tool handlers for MCP
â”œâ”€â”€ server.py                      # Original server (unchanged)
â””â”€â”€ server_dynamic.py              # Experimental server with tools-as-code
```

### Key Components

#### 1. ToolBase Class (`base.py`)

Base class for all tools with:
- `METADATA`: Tool metadata (name, description, category, tags)
- `InputSchema`: Pydantic model for input validation
- `OutputSchema`: Pydantic model for output structure
- `execute()`: Async method to run the tool logic

#### 2. ToolExecutor (`executor.py`)

Manages dynamic tool loading:
- `discover_all_tools()`: Scan filesystem for available tools
- `load_tool(name)`: Dynamically import and cache a tool
- `execute_tool(name, args, context)`: Load and run a tool
- `search_tools(query, category, tags, detail_level)`: Search for tools

#### 3. SearchTool (`search.py`)

The primary MCP tool that agents use to discover other tools.

## Usage

### Running the Experimental Server

The experimental server supports three modes via the `TOOLS_MODE` environment variable:

#### Mode 1: Pure Tools-as-Code (Default)

```bash
export TOOLS_MODE=search_only
export DATABASE_URI="teradatasql://user:pass@host/database"
python -m teradata_mcp.server_dynamic
```

**Behavior:**
- Only `search_tool` is exposed to agents
- Agents must use `search_tool` to discover other tools
- Maximum token efficiency (98.7% reduction)

#### Mode 2: Hybrid Mode

```bash
export TOOLS_MODE=hybrid
export DATABASE_URI="teradatasql://user:pass@host/database"
python -m teradata_mcp.server_dynamic
```

**Behavior:**
- All tools are exposed via the dynamic system
- Backward compatible with existing clients
- Allows gradual migration

#### Mode 3: Legacy Mode

```bash
python -m teradata_mcp.server  # Use original server
```

**Behavior:**
- Original static tool registration
- No changes to existing functionality

### Agent Workflow Example

```python
# 1. Agent starts with only search_tool available

# 2. Agent searches for database tools
result = call_tool("search_tool", {
    "category": "database",
    "detail_level": "standard"
})
# Returns: [
#   {"name": "query", "description": "Execute SQL...", "category": "database"},
#   {"name": "list_tables", "description": "List tables...", "category": "database"}
# ]

# 3. Agent needs full schema for a specific tool
result = call_tool("search_tool", {
    "query": "query",
    "detail_level": "full"
})
# Returns: Full input/output schemas for the query tool

# 4. Agent calls the discovered tool
result = call_tool("query", {
    "query": "SELECT * FROM database.table LIMIT 10"
})
```

## Creating New Tools

### Tool Template

```python
"""
My Tool - Brief description.
"""

from typing import Dict, Any
from pydantic import Field
import logging

from ..base import ToolBase, ToolInput, ToolOutput, ToolMetadata
from ...retry_utils import with_connection_retry

logger = logging.getLogger(__name__)


class MyToolInput(ToolInput):
    """Input schema for my_tool."""
    param1: str = Field(
        ...,
        description="Description of param1"
    )
    param2: int = Field(
        default=10,
        description="Description of param2"
    )


class MyToolOutput(ToolOutput):
    """Output schema for my_tool."""
    result: str = Field(
        default="",
        description="The result value"
    )


class MyTool(ToolBase):
    """
    Detailed description of what this tool does.

    Include examples, use cases, and any important notes.
    """

    METADATA = ToolMetadata(
        name="my_tool",
        description="Brief description for tool discovery",
        category="database",  # or "analytics", "system", etc.
        tags=["tag1", "tag2", "tag3"],
        requires_connection=True,
        requires_oauth=False
    )

    class InputSchema(MyToolInput):
        pass

    class OutputSchema(MyToolOutput):
        pass

    @with_connection_retry()  # Optional: for database operations
    async def execute(self, input_data: MyToolInput, context: Dict[str, Any]) -> MyToolOutput:
        """
        Execute the tool logic.

        Args:
            input_data: Validated input
            context: Execution context (connection_manager, db_name, etc.)

        Returns:
            Tool output
        """
        connection_manager = context.get('connection_manager')

        try:
            # Your tool logic here
            result = f"Processed {input_data.param1}"

            return MyToolOutput(
                success=True,
                result=result
            )
        except Exception as e:
            logger.error(f"Error in my_tool: {e}")
            return MyToolOutput(
                success=False,
                error=str(e)
            )
```

### Steps to Add a New Tool

1. **Create tool file** in appropriate category directory:
   ```bash
   touch src/teradata_mcp/tools/database/my_tool.py
   ```

2. **Implement the tool** using the template above

3. **Test the tool:**
   ```bash
   uv run python scripts/test-dynamic-tools.py
   ```

4. **Tool is automatically discovered** - no server restart needed in development!

## Testing

### Run All Tests

```bash
uv run python scripts/test-dynamic-tools.py
```

### Test Output

```
================================================================================
TESTING DYNAMIC TOOLS SYSTEM (Tools-as-Code Pattern)
================================================================================
TEST 1: Tool Discovery
  - query (database)
  - list_db (database)
  - list_tables (database)
  âœ… Tool discovery test passed!

TEST 2: Dynamic Tool Loading
  âœ… Loaded: QueryTool
  âœ… Tool loading test passed!

TEST 3: Search Tool Execution
  Found 4 tools matching 'database'
  âœ… Search tool execution test passed!

TEST 4: Tool Caching
  âœ… Caching test passed!

âœ… ALL TESTS PASSED!
```

### Manual Testing with MCP Inspector

```bash
# Start the server
export TOOLS_MODE=search_only
export DATABASE_URI="teradatasql://user:pass@host/database"
python -m teradata_mcp.server_dynamic

# In another terminal, use mcp-inspector or Claude Desktop
# Try calling search_tool to discover available tools
```

## Benefits

### 1. Token Efficiency
- **98.7% reduction** in initial tool loading
- Only load what you need, when you need it
- Scales to hundreds of tools without context bloat

### 2. Developer Experience
- **Easy to add new tools** - just create a file
- **Automatic discovery** - no manual registration
- **Type-safe** with Pydantic validation
- **Self-documenting** via metadata

### 3. Organization
- **Logical grouping** by category
- **Searchable** by tags and keywords
- **Clear interfaces** with input/output schemas

### 4. Performance
- **Lazy loading** - tools loaded on first use
- **Caching** - tools stay loaded in memory
- **Concurrent execution** - async by default

## Migration Guide

### From Traditional to Tools-as-Code

#### Step 1: Keep Original Server Running

```bash
# Original server still works
python -m teradata_mcp.server
```

#### Step 2: Test Experimental Server

```bash
# Try hybrid mode first
export TOOLS_MODE=hybrid
python -m teradata_mcp.server_dynamic
```

#### Step 3: Switch to Pure Tools-as-Code

```bash
# Maximum efficiency
export TOOLS_MODE=search_only
python -m teradata_mcp.server_dynamic
```

### Migrating Existing Tools

Convert a traditional tool to the new pattern:

**Before (fnc_tools.py):**
```python
async def execute_query(query: str) -> ResponseType:
    # Tool logic
    pass

# Manual registration in handle_list_tools()
types.Tool(
    name="query",
    description="Execute SQL",
    inputSchema={...}
)
```

**After (tools/database/query.py):**
```python
class QueryTool(ToolBase):
    METADATA = ToolMetadata(
        name="query",
        description="Execute SQL",
        category="database",
        tags=["sql"]
    )

    class InputSchema(ToolInput):
        query: str

    class OutputSchema(ToolOutput):
        results: List[Any]

    async def execute(self, input_data, context):
        # Same logic as before
        pass
```

**Benefits of migration:**
- âœ… Type safety
- âœ… Automatic discovery
- âœ… Better organization
- âœ… Reusable across different MCP servers

## Troubleshooting

### Tools Not Discovered

**Problem:** `search_tool` returns empty results

**Solution:**
1. Check tool files are in correct directory structure
2. Verify tool class inherits from `ToolBase`
3. Ensure `METADATA` attribute is defined
4. Run test script to verify discovery

### Import Errors

**Problem:** `ModuleNotFoundError` when loading tools

**Solution:**
1. Check Python path includes `src/`
2. Verify all `__init__.py` files exist
3. Use absolute imports in tool files

### Tool Not Executing

**Problem:** Tool loads but execution fails

**Solution:**
1. Check `InputSchema` matches arguments
2. Verify context contains required values (connection_manager, etc.)
3. Add logging to debug execution flow

## Future Enhancements

- [ ] Hot reload for development
- [ ] Tool versioning support
- [ ] Permission-based tool filtering
- [ ] Tool composition (tools calling tools)
- [ ] Performance metrics and analytics
- [ ] Tool marketplace/sharing

## Resources

- [Anthropic Article: Code Execution with MCP](https://www.anthropic.com/engineering/code-execution-with-mcp)
- [MCP Specification](https://modelcontextprotocol.io/)
- [FastMCP Documentation](https://github.com/jlowin/fastmcp)
- [Pydantic Documentation](https://docs.pydantic.dev/)

---

**Questions or Issues?**
Open an issue on GitHub or reach out to the development team!
